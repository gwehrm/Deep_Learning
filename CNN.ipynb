{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a Convolutional Neural Network for image classification with Keras:\n",
    "\n",
    "Used dataset: Traffic signs: kaggle.com/valentynsichkar/traffic-signs-preprocessed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data = pickle.load(open(\"data/data0.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_test', 'y_validation', 'x_validation', 'labels', 'x_train', 'y_test', 'y_train'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data is a dictionary with the following keys:\n",
    "# The dataset is already nicely prepared, therefore, no more preparation is needed. Even the splits\n",
    "# are already done!\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the datasets\n",
    "x_test = data[\"x_test\"]\n",
    "y_validation = data[\"y_validation\"]\n",
    "x_validation = data[\"x_validation\"]\n",
    "labels = data[\"labels\"]\n",
    "x_train = data[\"x_train\"]\n",
    "y_test = data[\"y_test\"]\n",
    "y_train = data[\"y_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the now obsolete original dataset\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the labels are not yet in a one-hot encoding \n",
    "display(y_test[1])\n",
    "\n",
    "# the labels are integers - therefore, the keras function to_categorical can be used to encode it\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# transformation:\n",
    "def ohe(labs):\n",
    "    ohe_labs = to_categorical(labs)\n",
    "    return ohe_labs\n",
    "y_test = ohe(y_test)\n",
    "display(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice, and the same with the others:\n",
    "y_validation = ohe(y_validation)\n",
    "y_train = ohe(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86989, 3, 32, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the shape of the training data\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(x_train/255.,[0,2,3,1])\n",
    "x_test = np.transpose(x_test/255.,[0,2,3,1])\n",
    "x_validation = np.transpose(x_validation/255.,[0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of classes:\n",
    "len(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "# Initialize the model object\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "               input_shape=(32,32,3)))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "# Add an output layer for the categories\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69591 samples, validate on 17398 samples\n",
      "Epoch 1/3\n",
      "69591/69591 [==============================] - 27s 386us/step - loss: 1.0152 - accuracy: 0.7632 - val_loss: 0.4729 - val_accuracy: 0.9002\n",
      "Epoch 2/3\n",
      "69591/69591 [==============================] - 27s 382us/step - loss: 0.3329 - accuracy: 0.9338 - val_loss: 0.3077 - val_accuracy: 0.9402\n",
      "Epoch 3/3\n",
      "69591/69591 [==============================] - 26s 377us/step - loss: 0.2038 - accuracy: 0.9602 - val_loss: 0.2446 - val_accuracy: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a8a22286d8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model \n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model on a training set\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4410/4410 [==============================] - 1s 157us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6844561925956181, 0.856916069984436]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model:\n",
    "model.evaluate(x_validation,y_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
