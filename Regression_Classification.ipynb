{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Classification in one Model\n",
    "\n",
    "Goal is to use one model for a regression and a classification. For that I go with the articles from watson.ch again. I want to predict the author of the article (classification) and the number of comments (regression) based on the article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import Python libaries needed for training embbeded vectors \n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "import time # for checking how long the training process takes\n",
    "import re\n",
    "import string\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import ipynb.fs.full.Classifier as cl#from https://github.com/ptnplanet/NLTK-Contributions/blob/master/ClassifierBasedGermanTagger/ClassifierBasedGermanTagger.py\n",
    "import random\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>nmbr_comments</th>\n",
       "      <th>themes</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tourismus-Professor pendelt mit Flugzeug zur A...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 22:15 28.03.19, 22:40</td>\n",
       "      <td>19</td>\n",
       "      <td>['Schweiz', 'Gesellschaft &amp; Politik', 'Klima']</td>\n",
       "      <td>['Naaa, wie kommt ihr so zur Uni? Mit dem Fahr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_title</td>\n",
       "      <td>no_author</td>\n",
       "      <td>no_date</td>\n",
       "      <td>no_comments</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\r\\n\\t\\tMit deiner Anmeldung erklärst du dic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anstatt mit Bus und Zug fahren mehr Menschen m...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 17:39</td>\n",
       "      <td>29</td>\n",
       "      <td>['Schweiz', 'Gesellschaft &amp; Politik', 'Mobilit...</td>\n",
       "      <td>['\\nDer Ausbau des öffentlichen Verkehrs würde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Über 80'000 Franken bei Online-Bank N26 geklau...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 17:34</td>\n",
       "      <td>18</td>\n",
       "      <td>['Digital', 'Schweiz', 'Datenschutz', 'Deutsch...</td>\n",
       "      <td>['\\nDie gefeierte Online-Bank N26 verspielt ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Der Wolf ist zurück – was auch Städter wissen ...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 16:19</td>\n",
       "      <td>45</td>\n",
       "      <td>['Schweiz', 'Wissen', 'Aargau', 'Natur', 'Tier']</td>\n",
       "      <td>['\\nDer gesetzliche Schutz des Wolfes wird der...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     author  \\\n",
       "0  Tourismus-Professor pendelt mit Flugzeug zur A...  no_author   \n",
       "1                                           no_title  no_author   \n",
       "2  Anstatt mit Bus und Zug fahren mehr Menschen m...  no_author   \n",
       "3  Über 80'000 Franken bei Online-Bank N26 geklau...  no_author   \n",
       "4  Der Wolf ist zurück – was auch Städter wissen ...  no_author   \n",
       "\n",
       "                              date nmbr_comments  \\\n",
       "0  28.03.19, 22:15 28.03.19, 22:40            19   \n",
       "1                          no_date   no_comments   \n",
       "2                 28.03.19, 17:39             29   \n",
       "3                 28.03.19, 17:34             18   \n",
       "4                 28.03.19, 16:19             45   \n",
       "\n",
       "                                              themes  \\\n",
       "0     ['Schweiz', 'Gesellschaft & Politik', 'Klima']   \n",
       "1                                                 []   \n",
       "2  ['Schweiz', 'Gesellschaft & Politik', 'Mobilit...   \n",
       "3  ['Digital', 'Schweiz', 'Datenschutz', 'Deutsch...   \n",
       "4   ['Schweiz', 'Wissen', 'Aargau', 'Natur', 'Tier']   \n",
       "\n",
       "                                             article  \n",
       "0  ['Naaa, wie kommt ihr so zur Uni? Mit dem Fahr...  \n",
       "1  ['\\r\\n\\t\\tMit deiner Anmeldung erklärst du dic...  \n",
       "2  ['\\nDer Ausbau des öffentlichen Verkehrs würde...  \n",
       "3  ['\\nDie gefeierte Online-Bank N26 verspielt ge...  \n",
       "4  ['\\nDer gesetzliche Schutz des Wolfes wird der...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "articles = pd.read_csv(\"C:\\\\Users\\\\gwehrm\\\\Documents\\\\Repos\\\\watson_analysis\\\\watson_schweiz.csv\",sep = \";\")\n",
    "articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>nmbr_comments</th>\n",
       "      <th>themes</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title  date  nmbr_comments  themes  article\n",
       "author                                             \n",
       "1          63    63             63      63       63\n",
       "5         113   113            113     113      113\n",
       "7         149   149            149     149      149\n",
       "15        104   104            104     104      104\n",
       "16        152   152            152     152      152\n",
       "19        155   155            155     155      155\n",
       "28         52    52             52      52       52\n",
       "42        133   133            133     133      133\n",
       "49         99    99             99      99       99\n",
       "57         60    60             60      60       60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter no_author\n",
    "data_reduced = articles[-articles['author'].str.contains(\"no_author\")]\n",
    "# authors_article = data_reduced.groupby('author').count().reset_index()\n",
    "# for simplicity I will reduce the number of authors. I set a threshold of minimum 50 articles \n",
    "\n",
    "\n",
    "# Importing necessary libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data_reduced[\"author\"] = labelencoder.fit_transform(data_reduced[\"author\"])\n",
    "\n",
    "\n",
    "g = data_reduced.groupby('author')\n",
    "data_reduced = g.filter(lambda x: len(x) > 50).reset_index(drop = True)\n",
    "display(data_reduced.groupby('author').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "exclude = set(string.punctuation)\n",
    "for index,s in enumerate(data_reduced[\"article\"]):\n",
    "    exclude = set(string.punctuation)\n",
    "    data_reduced.loc[index,\"article\"]= ''.join(ch for ch in s if ch not in exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>nmbr_comments</th>\n",
       "      <th>themes</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zielscheibe der Wut – Tamara Funiciello auf de...</td>\n",
       "      <td>49</td>\n",
       "      <td>28.03.19, 11:28 28.03.19, 12:40</td>\n",
       "      <td>392</td>\n",
       "      <td>['Schweiz', 'Facebook', 'Feminismus', 'Gesells...</td>\n",
       "      <td>nTamara Funiciello JusoPräsidentin und Zielsch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der Hass im Netz nimmt zu – was bedeutet das f...</td>\n",
       "      <td>57</td>\n",
       "      <td>27.03.19, 10:29 27.03.19, 18:58</td>\n",
       "      <td>26</td>\n",
       "      <td>['Schweiz', 'Best of watson', 'Facebook', 'Ges...</td>\n",
       "      <td>Die aktuelle Kriminalstatistik zeigt deutlich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Der Kampf um den Waschturm  – ein Zürcher Krie...</td>\n",
       "      <td>57</td>\n",
       "      <td>26.03.19, 09:26 27.03.19, 01:36</td>\n",
       "      <td>70</td>\n",
       "      <td>['Schweiz', 'Best of watson', 'Gesellschaft &amp; ...</td>\n",
       "      <td>Tatort Ein Mehrfamilienhaus in Zürich Wipkinge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Das ist erst der Anfang»: So reagiert die Kli...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.03.19, 18:42 26.03.19, 11:01</td>\n",
       "      <td>41</td>\n",
       "      <td>['Schweiz', 'Best of watson', 'Klima', 'Klimas...</td>\n",
       "      <td>Die KlimastreikBewegung feiert mit dem Erdruts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warum das Klima rockt und Europa nicht: 5 Erke...</td>\n",
       "      <td>42</td>\n",
       "      <td>25.03.19, 14:53 26.03.19, 06:49</td>\n",
       "      <td>33</td>\n",
       "      <td>['Schweiz', 'BDP', 'Best of watson', 'CVP', 'F...</td>\n",
       "      <td>nDie Parteipräsidenten Konrad Langhart SVP lin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  author  \\\n",
       "0  Zielscheibe der Wut – Tamara Funiciello auf de...      49   \n",
       "1  Der Hass im Netz nimmt zu – was bedeutet das f...      57   \n",
       "2  Der Kampf um den Waschturm  – ein Zürcher Krie...      57   \n",
       "3  «Das ist erst der Anfang»: So reagiert die Kli...       1   \n",
       "4  Warum das Klima rockt und Europa nicht: 5 Erke...      42   \n",
       "\n",
       "                              date nmbr_comments  \\\n",
       "0  28.03.19, 11:28 28.03.19, 12:40           392   \n",
       "1  27.03.19, 10:29 27.03.19, 18:58            26   \n",
       "2  26.03.19, 09:26 27.03.19, 01:36            70   \n",
       "3  25.03.19, 18:42 26.03.19, 11:01            41   \n",
       "4  25.03.19, 14:53 26.03.19, 06:49            33   \n",
       "\n",
       "                                              themes  \\\n",
       "0  ['Schweiz', 'Facebook', 'Feminismus', 'Gesells...   \n",
       "1  ['Schweiz', 'Best of watson', 'Facebook', 'Ges...   \n",
       "2  ['Schweiz', 'Best of watson', 'Gesellschaft & ...   \n",
       "3  ['Schweiz', 'Best of watson', 'Klima', 'Klimas...   \n",
       "4  ['Schweiz', 'BDP', 'Best of watson', 'CVP', 'F...   \n",
       "\n",
       "                                             article  \n",
       "0  nTamara Funiciello JusoPräsidentin und Zielsch...  \n",
       "1  Die aktuelle Kriminalstatistik zeigt deutlich ...  \n",
       "2  Tatort Ein Mehrfamilienhaus in Zürich Wipkinge...  \n",
       "3  Die KlimastreikBewegung feiert mit dem Erdruts...  \n",
       "4  nDie Parteipräsidenten Konrad Langhart SVP lin...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_reduced.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gwehrm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dowloading the stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dowloaded corpus \n",
    "corp = nltk.corpus.ConllCorpusReader('C:\\\\Users\\\\gwehrm\\\\Documents', 'tiger_release_aug07.corrected.16012013.conll09',\n",
    "                                     ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n",
    "                                     encoding='utf-8')\n",
    "\n",
    "tagged_sents = list(corp.tagged_sents())\n",
    "random.shuffle(tagged_sents)\n",
    "\n",
    "# set a split size: use 90% for training, 10% for testing\n",
    "split_perc = 0.1\n",
    "split_size = int(len(tagged_sents) * split_perc)\n",
    "train_sents, test_sents = tagged_sents[split_size:], tagged_sents[:split_size]\n",
    "\n",
    "# from ClassifierBasedGermanTagger\n",
    "#train the classifier ()\n",
    "tagger = cl.ClassifierBasedGermanTagger(train=train_sents)\n",
    "\n",
    "from germalemma import GermaLemma\n",
    "lemmatizer = GermaLemma()\n",
    "\n",
    "accuracy = tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411487917184822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the accuracy of the classifier \n",
    "display(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# in a list comprehension, first tag the word correctly and remove if it is a german stopword\n",
    "for index,article in enumerate(data_reduced[\"article\"]):\n",
    "    data_reduced[\"article\"][index]= tagger.tag([word for word in article.split() if word.lower() not in stopwords.words('german')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the stem of the word, lemmatization needs to be done for each word\n",
    "# with thelp of the tagged word, it works\n",
    "\n",
    "from germalemma import GermaLemma\n",
    "lemmatizer = GermaLemma()\n",
    "# passing the word and the POS tag \n",
    "for index, tos in enumerate(data_reduced[\"article\"]):\n",
    "    article_w=[]\n",
    "    for i in tos:\n",
    "        try:\n",
    "            word, N = i\n",
    "            lemma = lemmatizer.find_lemma(word,N)\n",
    "            article_w.append(lemma)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    data_reduced.at[index,\"article\"] = article_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [ntamara, Funiciello, JusoPräsidentin, Zielsch...\n",
       "1       [aktuell, Kriminalstatistik, zeigen, deutlich,...\n",
       "2       [Tatort, Mehrfamilienhaus, Zürich, Wipkingen, ...\n",
       "3       [KlimastreikBewegung, feiern, Erdrutschsieg, Ö...\n",
       "4       [Parteipräsident, Konrad, Langhart, SVP, links...\n",
       "5       [nbesuch, Reitschule, Polizei, Seite, toben, S...\n",
       "6       [n«i, schänken, Motto, jung, SRFArena, Thema, ...\n",
       "7       [nsvppräsident, Albert, Rösti, Fraktionschef, ...\n",
       "8       [Gesellschaft, reich, heißen, glücklich, sagen...\n",
       "9       [nsbbkund, GA, weiterhin, online, hinterlegen,...\n",
       "10      [nfranziska, Roth, Wahl, heute, glücklich, Bil...\n",
       "11      [nbild, KEYSTONE, Wahl, Kanton, Zürich, gelten...\n",
       "12      [ntschüss, Schweiz, teuer, Ausbildung, müssen,...\n",
       "13      [Welt, sehen, haben, Mr, Bean, UK, Sagen, bild...\n",
       "14      [n20, diskutiert, Studio, kündigen, gleich, ba...\n",
       "15      [Gang, Öffentlichkeit, Stefan, Locher, Beginn,...\n",
       "16      [nthomas, Ahlburg, neu, Superzug, Stadler, gen...\n",
       "17      [nzürch, protestieren, gut, Klimapolitik, Sams...\n",
       "18      [npati, Jann, möchten, schon, bald, klimaklost...\n",
       "19      [Freitag, zehntausenden, Schüler, ganz, Welt, ...\n",
       "20      [Swiss, befördern, immer, Passagier, KlimaDeba...\n",
       "21      [nschrei, gut, Zukunft, Schüler, streiken, Luz...\n",
       "22      [nde, FDPKantonsrat, Thomas, Vogel, Kleber, «d...\n",
       "23      [naktivist, Einreichung, Konzernverantwortungs...\n",
       "24      [Grüne, liebäugeln, bereits, Woche, Flugverbot...\n",
       "25      [nzwei, Heu, gleich, Bühne, Ungarns, Ministerp...\n",
       "26      [Klimawahljahr, lancieren, SP, reichen, Flut, ...\n",
       "27      [nedith, Loosli, Gedanke, Zukunft, screenshoen...\n",
       "28      [nchristian, Brunner, setzen, tausend, Frau, B...\n",
       "29      [nnationalrat, Gewerkschafter, Corrado, Pardin...\n",
       "                              ...                        \n",
       "1050    [Beitrag, teilen, Morena, ln, Swiss, Blogger, ...\n",
       "1051    [Filippo, Leuteneggers, Medienpräsenz, steigen...\n",
       "1052    [Monat, stimmen, Reform, Altersvorsorge, haben...\n",
       "1053    [nbild, KEYSTONE, Bern, demonstrieren, heute, ...\n",
       "1054    [Plakat, Kampagne, Bild, KEYSTONE, DernArbeitg...\n",
       "1055    [ndies, Brief, liegen, zurzeit, briefkäst, Per...\n",
       "1056    [nmoderator, Projer, versuchen, Bundesrat, Sch...\n",
       "1057    [ntrumps, Gesicht, Bitterkeit, finden, Grob, m...\n",
       "1058    [nignazio, Cassis, Isabelle, Moret, Pierre, Ma...\n",
       "1059    [nein, siebenköpfig, Mensch, vermessen, werden...\n",
       "1060    [nde, Newsroom, Bild, KEYSTONE, müssen, Millio...\n",
       "1061    [ngiannina, Blanco, Franke, Monat, leistenxa0e...\n",
       "1062    [nalexand, Segert, Gerichtstermin, Österreich,...\n",
       "1063    [nmedienexpert, Otfried, Jarren, fordern, Einf...\n",
       "1064    [ngar, anonym, Projekt, zürcher, miteinander, ...\n",
       "1065    [ndenkbar, zürcher, parkiert, gelbgrau, pinken...\n",
       "1066    [erstmals, Forscher, untersuchen, häufig, haus...\n",
       "1067    [n, Schweden, sorgen, Modekette, HM, Unmut, So...\n",
       "1068    [nwird, Autoprüfung, Zukunft, Automatikgetrieb...\n",
       "1069    [Deutschschweizer, Erziehungsdirektoren, Konfe...\n",
       "1070    [nnadin, Nonn, links, Jahr, kehren, Schweiz, R...\n",
       "1071    [nbild, KEYSTONE, Schweiz, gerne, RecyclingWel...\n",
       "1072    [nnenad, Stojanović, Politologe, untersuchen, ...\n",
       "1073    [nein, Stück, Papier, sorgen, Aufruhr, Aushang...\n",
       "1074    [nluzian, Franzini, schenken, bilden, watsonch...\n",
       "1075    [nerich, Hess, verstossen, bilden, keystonen, ...\n",
       "1076    [nvor, ländlich, Gebiet, Christoph, Blocher, M...\n",
       "1077    [ndies, Schild, hängen, Samstag, Sonntag, Pool...\n",
       "1078    [nberuflich, ermorden, David, Bild, KEYSTONE, ...\n",
       "1079    [nwar, SwissMitarbeitern, beliebt, Bild, KEYST...\n",
       "Name: article, Length: 1080, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduced[\"article\"]\n",
    "# the articles are empty..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
